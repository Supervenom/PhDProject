\documentclass[english]{scrartcl}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{microtype}
\addtokomafont{disposition}{\rmfamily}
\usepackage{babel}
\usepackage[utf8]{inputenc}

\begin{document}
\title{Research project proposal}
\subtitle{Computability and complexity of optimal reductions in functional programming languages}
\author{Gabriele Vanoni}
\date{}
\maketitle
\section{State of the art}
There are different possible \emph{strategies} when you have to evaluate expressions. Some are better than others, in the sense that bring you to the result in a lower number of steps. Since programs in pure functional languages are essentially expressions, the problem of defining good strategies is particularly interesting. Finding minimal strategies, i.e. strategies that minimize the number of steps, seems even more interesting. However this problem has been proven undecidable for the $\lambda$-calculus \cite[Section~13.5]{barendregt_lambda_1984}, \emph{the} paradigmatic pure functional language. Though researchers have not abandoned the field and since ``optimality and computability cannot be both achieved at the same time, the trick consists in a change of granularity'' \cite{terese_term_2003}. Around 40 years ago Jean-Jacques Lévy introduced the notion of \emph{optimal reduction}, where optimal roughly means without duplication of reduction work and without any useless computation \cite{levy_reductions_1978}. He proved that such a strategy exists and is recursive but he wasn't able to provide an actual implementation by means of real data structures. After more than 10 years Lamping and Kathail indipendently proposed the first algorithms to actually implement optimal reductions in the Lévy sense  \cite{lamping_algorithm_1990,kathail_optimal_1990}. Lamping's algorithm implemented optimal reductions by means of the so called \emph{sharing graphs} with some \emph{rewriting rules} sound with respect to Lévy specification. The algorithm captured the interest of the community, that began to work trying to simplify and better understand it. The research on this topic took different branches.
\paragraph{Mathematical foundations of optimal reductions}
\paragraph{Cost models for the $\lambda$-calculus}
\paragraph{Optimal implementation of functional programming languages.}Soon after the publication of Lamping's algorithm researchers tried to extend his method to real functional programming languages, since coding everything as $\lambda$-terms is clearly infeasible. \emph{Interaction systems} \cite{asperti_interaction_1994, asperti_interaction_1996} are the technical tool developed for this reason and allowed Lamping's algorithm to work with a larger and more flexible calculus featuring for example inductive data types, conditionals and recursion. The \emph{Bologna Optimal Higher-Order Machine} (BOHM) was the first prototype implementation of these ideas \cite{asperti_bologna_1996}. It was written in C and was an interpreter for a sugared $\lambda$-calculus enriched with booleans, integers, lists and basic operations on these data types. Benchmarks in \cite{asperti_optimal_1998} showed that BOHM outperformed both Caml Light and Haskell on pure $\lambda$-terms and was comparable on typical symbolic computations. \cite{asperti_optimal_1998} contains a self-contained treatment of the whole material behind optimal reductions, from the mathematical theory to the more practical aspects of the implementation, such as garbage collection.
\section{Project description}
\section{Expected results}
\bibliographystyle{alpha}
\bibliography{project}
\end{document}